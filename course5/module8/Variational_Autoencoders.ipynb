{"cells":[{"cell_type":"markdown","id":"3bd43de2-0d1b-4f13-9491-722e404859a3","metadata":{},"source":["<center>\n","    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"300\" alt=\"cognitiveclass.ai logo\"  />\n","</center>\n"]},{"cell_type":"markdown","id":"baf8a3d1-3b33-4b6d-8573-5b37dd91dc7b","metadata":{},"source":["# Variational Autoencoders\n"]},{"cell_type":"markdown","id":"105a89f9-544a-4501-8812-69c4b719fd02","metadata":{},"source":["Estimated time needed: **25** minutes\n"]},{"cell_type":"markdown","id":"8d95a260-1ba8-4e3a-b85f-2543fb43e9a6","metadata":{},"source":["Variational Autoencoders are a type of deep learning generative model. Once you train them on sufficiently large datasets and let them learn latent representations of the data, they can be used to draw faces, plot digits, produce music, and generate anything you can think of.\n","\n","<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML311-Coursera/images/vae_intro.jpg\" width=60%>\n"]},{"cell_type":"markdown","id":"172ccf2a-98e4-49a4-bfe8-f4a7aa4bed8d","metadata":{},"source":["In this lab, we will study the architecture of VAEs. We will build a VAE ourselves using Keras and train the model on the MNIST digits dataset, so that they can be used to generate new images of digits.\n"]},{"cell_type":"markdown","id":"ae23ee74-380c-4330-9bff-d84fe0f59b7c","metadata":{},"source":["## **Table of Contents**\n","\n","<ol>\n","    <li><a href=\"https://#Objectives\">Objectives</a></li>\n","    <li>\n","        <a href=\"https://#Setup\">Setup</a>\n","        <ol>\n","            <li><a href=\"https://#Installing-Required-Libraries\">Installing Required Libraries</a></li>\n","            <li><a href=\"https://#Importing-Required-Libraries\">Importing Required Libraries</a></li>\n","            <li><a href=\"https://#Defining-Helper-Functions\">Defining HelperFunctions<a></li>\n","        </ol>\n","    </li>\n","    <li>\n","        <a href=\"https://#Dataset\">Prepare Dataset</a>\n","    </li>  \n","    <li>\n","        <a href=\"https://#Variational-Autoencoder\">Variational Autoencoder</a>\n","    </li>\n","        <li>\n","        <a href=\"https://#Encoder Part\">Encoder Part</a>\n","    </li>\n","     <li>\n","        <a href=\"https://#Decoder Part\">Decoder Part</a>\n","    </li>\n","         <li>\n","        <a href=\"https://#Loss-function\">Loss function </a>\n","    </li>\n","      <li>\n","        <a href=\"https://#Putting-it all together\">Putting it all together  </a>\n","    </li>\n","    <li><a href=\"https://#Training the VAE\">Training the VAE</a></li>\n","\n","</ol>\n"]},{"cell_type":"markdown","id":"48afec55-670d-472c-96bf-356f753f4865","metadata":{},"source":["## Objectives\n","\n","After completing this lab you will be able to:\n","\n","*   Understand the architecture of a Variational Autoencoder\n","*   Build and train Variational Autoencoder in Keras\n"]},{"cell_type":"markdown","id":"6f7843ea-6f06-49ed-963a-0e1206b9b941","metadata":{},"source":["***\n"]},{"cell_type":"markdown","id":"c24b41ed-118d-4020-b970-cabf4137b76f","metadata":{},"source":["## Setup\n"]},{"cell_type":"markdown","id":"598a2192-addd-4901-9f32-9b5cb7ad3d85","metadata":{},"source":["For this lab, we will be using the following libraries:\n","\n","*   [`pandas`](https://pandas.pydata.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for managing the data.\n","*   [`numpy`](https://numpy.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for mathematical operations.\n","*   [`sklearn`](https://scikit-learn.org/stable/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for machine learning and machine-learning-pipeline related functions.\n","*   [`seaborn`](https://seaborn.pydata.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for visualizing the data.\n","*   [`matplotlib`](https://matplotlib.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for additional plotting tools.\n"]},{"cell_type":"markdown","id":"2f5ca7c7-5915-48e3-85d6-916e641bc984","metadata":{},"source":["### Installing Required Libraries\n","\n","The following required libraries are pre-installed in the Skills Network Labs environment. However, if you run these notebook commands in a different Jupyter environment (like Watson Studio or Ananconda), you will need to install these libraries by removing the `#` sign before `!mamba` in the code cell below.\n"]},{"cell_type":"code","execution_count":null,"id":"28f8ab99-a106-4dfd-a2b9-e6c085528a23","metadata":{},"outputs":[],"source":["# All Libraries required for this lab are listed below. The libraries pre-installed on Skills Network Labs are commented.\n","# !mamba install -qy pandas==1.3.4 numpy==1.21.4 seaborn==0.9.0 matplotlib==3.5.0 scikit-learn==0.20.1\n","# Note: If your environment doesn't support \"!mamba install\", use \"!pip install\""]},{"cell_type":"markdown","id":"bc093db1-0e7e-406e-9c01-cefb30e8149e","metadata":{},"source":["Run the following upgrade and then **RESTART YOUR KERNEL**. Make sure the version of tensorflow imported below is **no less than 2.9.0**.\n"]},{"cell_type":"code","execution_count":null,"id":"80d8cdae-6c1d-44f7-a911-59a428d1e7b8","metadata":{},"outputs":[],"source":["%%capture\n","!pip3 install --upgrade tensorflow"]},{"cell_type":"markdown","id":"38481da1-a2d2-41f6-851c-346f70a1b2db","metadata":{},"source":["### Importing Required Libraries\n","\n","*We recommend you import all required libraries in one place (here):*\n"]},{"cell_type":"code","execution_count":1,"id":"786826df-f4f0-4745-babe-d530fe13becc","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["2.18.0-dev20240815\n"]}],"source":["# You can use this section to suppress warnings generated by your code:\n","def warn(*args, **kwargs):\n","    pass\n","import warnings\n","warnings.warn = warn\n","warnings.filterwarnings('ignore')\n","\n","import os\n","import numpy as np\n","\n","# Import the keras library\n","import tensorflow as tf\n","print(tf.__version__)\n","from tensorflow import keras\n","from tensorflow.keras import Model\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense,Layer,Reshape,Conv2DTranspose\n","from tensorflow.python.client import device_lib\n","from keras.layers import Multiply, Add\n","from keras import backend as K\n","\n","from numpy import random\n","\n","from matplotlib import pyplot as plt"]},{"cell_type":"markdown","id":"4adc4522-e613-4bad-b09f-b9453f8cbb9c","metadata":{},"source":["### Defining Helper Functions\n"]},{"cell_type":"code","execution_count":2,"id":"16fecd5f-5935-4cd6-883c-bb3ccb785ee1","metadata":{},"outputs":[],"source":["def plot_label_clusters(model, data, labels):\n","    # display a 2D plot of the digit classes in the latent space\n","    z_mean, _, _ =encoder.predict(data)\n","    plt.figure(figsize=(8, 6))\n","    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=labels)\n","    plt.colorbar()\n","    plt.xlabel(\"z[0]\")\n","    plt.ylabel(\"z[1]\")\n","    plt.show()"]},{"cell_type":"markdown","id":"b7c14c90-75cf-4792-986a-37e3d40c959f","metadata":{},"source":["## Preparing the Dataset\n"]},{"cell_type":"markdown","id":"adf796cb-b260-4594-805e-8cc8ec68300b","metadata":{},"source":["We load the MNIST handwritten digit dataset:\n"]},{"cell_type":"code","execution_count":3,"id":"a68fbbc5-861d-46cf-ac08-cda7e6eba298","metadata":{},"outputs":[],"source":["# Import data\n","(X_train, y_train), (_, _) = keras.datasets.mnist.load_data()"]},{"cell_type":"markdown","id":"7dba1690-f179-419e-bb8c-141cdbea3bd1","metadata":{},"source":["There are 60000 $28 \\times 28$ images in the training set:\n"]},{"cell_type":"code","execution_count":4,"id":"fb002833-0de9-4cdc-9f3b-0b916866f993","metadata":{},"outputs":[{"data":{"text/plain":["((60000, 28, 28), (60000,))"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["X_train.shape, y_train.shape"]},{"cell_type":"markdown","id":"4f79c93b-ac25-434a-84a5-695d32fc898a","metadata":{},"source":["Let's look at the unique labels of the digits that we want to predict:\n"]},{"cell_type":"code","execution_count":5,"id":"7b5deadf-e622-4650-af00-18c2b28cb0b3","metadata":{},"outputs":[{"data":{"text/plain":["array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["np.unique(y_train)"]},{"cell_type":"markdown","id":"c9d950fa-0702-45c3-b67c-5803c334ce4d","metadata":{},"source":["We will reshape the training set to $60000 \\times 28 \\times 28 \\times 1$ to work with convolutions. 1 indicates that the input images only have one channel, that is: grayscale images.\n"]},{"cell_type":"code","execution_count":6,"id":"66bf78cf-019e-408c-aef2-9ca7ac6d1baa","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Before reshaping, X_train has a shape of: (60000, 28, 28)\n","After reshaping, X_train has a shape of: (60000, 28, 28, 1)\n"]}],"source":["print(f\"Before reshaping, X_train has a shape of: {X_train.shape}\")\n","\n","X_train = X_train.reshape((X_train.shape[0],X_train.shape[1],X_train.shape[2],1))\n","print(f\"After reshaping, X_train has a shape of: {X_train.shape}\")"]},{"cell_type":"markdown","id":"3735283c-b937-4670-bd59-b0c82ff3ab1e","metadata":{},"source":["We cast the data type of `X_train` to `tf.float32` and normalize its values to range from 0 to 1:\n"]},{"cell_type":"code","execution_count":7,"id":"2b679d93-ed9d-40a0-b7ca-d9d05b20db05","metadata":{},"outputs":[],"source":["X_train = tf.cast(X_train, tf.float32)\n","X_train = X_train/255.0"]},{"cell_type":"markdown","id":"eea595c8-3110-4979-b60b-edeebe9b1be2","metadata":{},"source":["We convert the tensors to a `tf.data.Dataset` object.\n"]},{"cell_type":"code","execution_count":8,"id":"3e1807d2-82b2-4cd7-96df-e974a1ec3760","metadata":{},"outputs":[{"data":{"text/plain":["<_TensorSliceDataset element_spec=TensorSpec(shape=(28, 28, 1), dtype=tf.float32, name=None)>"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["dataset=tf.data.Dataset.from_tensor_slices(X_train)\n","dataset"]},{"cell_type":"markdown","id":"8a1e1661-7dc7-44fe-81a4-01b71095b166","metadata":{},"source":["We can plot five random samples from the training set:\n"]},{"cell_type":"code","execution_count":9,"id":"20cb91d4-9013-40c2-a2bf-5b69c9f73449","metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 300x300 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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","text/plain":["<Figure size 300x300 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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","text/plain":["<Figure size 300x300 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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","text/plain":["<Figure size 300x300 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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","text/plain":["<Figure size 300x300 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["for r in random.randint(0, 59999, size=5, dtype=int):\n","    \n","    plt.figure(figsize=(3,3))\n","    plt.imshow(X_train[r,:,:,0],cmap=\"gray\")\n","    plt.title(\"sample No.{} belongs to class {}\".format(r,y_train[r]))\n","    plt.axis(\"off\")"]},{"cell_type":"markdown","id":"3f8bdd52-908b-4674-8036-141425b12cce","metadata":{},"source":["## Variational Autoencoder\n","\n","In a nutshell, the architecture of a VAE is similar to that of a standard Autoencoder such that it consists of an encoder and a decoder, both of which are trained to minimize the reconstruction error between the original data $X$ and the encoded-decoded data $\\hat X$.\n","\n","The training samples $X$ are passed to the encoder to generate samples $\\boldsymbol z$, which are mappings of $X$ in the latent space.  The decoder then uses $\\boldsymbol z$ to generate the most likely reconstruction $\\hat X$.\n","\n","At this point, a natural question that comes in mind is, how do we use VAEs to generate meaningful content? You might think that if we train a VAE on images, then we can use it to generate new images. However, since it's difficult to regularize what happens to our encoder output in the latent space, we can't be sure that the encoder will organize information in the latent space in a way that the decoder can easily take that information and generates content that seems reasonable.\n","\n","Hence, in order to be able to use the VAE for meaningful generative purposes, we need to introduce some regularization into the latent space. As shown in the diagram below, **instead of mapping the input to a single point in the latent space, we encode it as a normal distribution by returning the mean and standard deviation of the distribution**. By doing so, the decoder would be able to use the regularized information to construct new content.\n","\n","In the following sections, we will build a VAE by following the architecture in the illustrative diagram below.\n"]},{"cell_type":"markdown","id":"46e41322-24de-4f12-ad73-f898fa86ff74","metadata":{},"source":[" <center>\n","    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML311-Coursera/labs/autoencoder.png\"\" width=\"800\" alt=\"computer components\"  />\n","<center>\n"]},{"cell_type":"markdown","id":"31747b08-b8a8-478b-a14f-fbc9e85cf47c","metadata":{},"source":["## Encoder Part\n","\n","We build the encoder part by breaking it up into three smaller parts.\n","\n","The **first part** of the encoder consists of several fully connected layers, as shown in the picture below, which encodes the high-dimensional input; For our implementation, we will use two **convolution layers** since we want the model to learn the image data using convolutions.\n","\n","<center><img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML311-Coursera/labs/encoder.png\" width=\"30%\" alt=\"computer components\"/></center>\n"]},{"cell_type":"markdown","id":"bc93f0b2-656c-4ec9-b871-1098058af273","metadata":{},"source":["Here is the code for building the first part of the encoder. The `encoder_output` that comes out of the convolution layers is denoted as $\\boldsymbol z^2$.\n"]},{"cell_type":"code","execution_count":10,"id":"beb635d9-ab2b-4953-ae12-c916bbc34ac7","metadata":{},"outputs":[],"source":["encoder_input= keras.Input(shape=(28, 28, 1))\n","x = Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_input)\n","x = Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n","x = Flatten()(x)\n","encoder_output = Dense(16, activation=\"relu\")(x)"]},{"cell_type":"markdown","id":"ea5c0d67-fd0b-4e51-919a-ad3dee62eee2","metadata":{},"source":["The **second part** of the encoder represents a normal distribution over the latent space that takes the `encoder_output` and gives you the probability of it belonging to the distribution.\n","\n","The mean and standard deviation of the normal distribution will be learned and then used to calculate the log-likelihood for optimization purposes.\n"]},{"cell_type":"markdown","id":"7278cfdb-0728-44f1-84eb-a1a6d5b45041","metadata":{},"source":[" <center>\n","    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML311-Coursera/labs/mean_var.png\" width=\"400\" alt=\"computer components\"  />\n","<center>\n"]},{"cell_type":"markdown","id":"a9c722cd-3ee6-4459-958d-5182a4a88613","metadata":{},"source":["To implement the second part, we create **two Dense layers** in parallel for the model to learn the **mean** and **log variance** respectively; We want the model to learn the log variance instead of the variance because it brings more stability and ease of training. The detailed reason is as follows:\n","\n","*   By definition, $\\sigma$ is a non-negative real number. To enforce this, we would need to use the ReLU activation to obtain such a value, but the gradient is not well defined around zero.\n","*   Besides, since we typically apply normalization methods in model training, the data values range from 0 to 1, which means the standard deviation of those values is also very small. This adds a burden to the optimization process and causes numerical instabilities as the gradients flowing in the backpropagation will contain floating points.\n","\n","Note that we can convert the log variance to the standard deviation using the exponential function. Here is the code for building the second part:\n"]},{"cell_type":"code","execution_count":17,"id":"877db953-1ea5-43ee-989f-743c92312469","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From c:\\GitHub\\IBM_Machine_Learning\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:204: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n"]}],"source":["from tensorflow.keras.layers import Lambda\n","latent_dim = 2\n","\n","# Dense layer to learn the mean\n","mean = Dense(latent_dim, name=\"mean\")(encoder_output)\n","# Dense layer to learn the log variance\n","log_var = Dense(latent_dim, name=\"z_log_var\")(encoder_output)\n","\n","# sigmia is calculated from log variance\n","# Apply the tf.exp operation within a Lambda layer\n","sigma = Lambda(lambda x: tf.exp(0.5 * x), name=\"sigma\")(log_var)"]},{"cell_type":"markdown","id":"4862c356-edba-4da0-852d-983eeb3feaba","metadata":{},"source":["Here comes the **third part** of the encoder, where we sample a point from the learned distribution in the latent space. The sampled point will later be decoded by the decoder to generate new content.\n","\n","The following diagram illustrates the random sampling:\n","\n","<center>\n","    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML311-Coursera/labs/repramateriztion.png\" width=\"400\" alt=\"computer components\"  />\n","<center> \n"]},{"cell_type":"markdown","id":"e21a47c3-a2e2-4a22-9f09-b264f917a4e9","metadata":{},"source":["The sampled point, denoted by $\\boldsymbol z^5$ in the diagram, comes from a normal distribution with mean $\\mu$ and standard deviation $\\sigma$, with some random noise $\\epsilon$.\n"]},{"cell_type":"code","execution_count":21,"id":"774110fb-40e1-4abd-a3b8-76815adf959c","metadata":{},"outputs":[],"source":["# random normal noise \n","\n","# Assuming `mean` is a KerasTensor\n","def sampling(args):\n","    mean, log_var = args\n","    batch = tf.shape(mean)[0]\n","    dim = tf.shape(mean)[1]\n","    epsilon = tf.random.normal(shape=(batch, dim))\n","    return mean + tf.exp(0.5 * log_var) * epsilon\n","\n","# Create the Lambda layer\n","epsilon = Lambda(sampling, name=\"sampling\")([mean, log_var])"]},{"cell_type":"markdown","id":"3f51951c-ff65-4d7b-9d56-b5143470b80c","metadata":{},"source":["Due to the random sampling of $\\boldsymbol z^5$, we use the [Reparameterization Trick](https://gregorygundersen.com/blog/2018/04/29/reparameterization/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML311Coursera35714171-2022-01-01) $ z = \\mu + \\sigma \\odot \\epsilon$, which allows the VAE to backpropagate through a random node.\n"]},{"cell_type":"code","execution_count":22,"id":"119527b5-68db-4796-83b9-1b3f64fdc20b","metadata":{},"outputs":[],"source":["#z = mean + sigma * epsilon \n"," \n","z_eps = Multiply()([sigma, epsilon])\n","z = Add()([mean, z_eps])"]},{"cell_type":"markdown","id":"ba1b2a98-691b-43b6-8d7b-69fdd4608e99","metadata":{},"source":["The encoder will output the `mean` and `log_var` of the learned distribution as well as the sampled point `z`. Now, we create the complete encoder network by chaining the `encoder_input` and the `outputs`:\n"]},{"cell_type":"code","execution_count":23,"id":"cfd2dc00-c568-4bac-8fa2-83e62487a68b","metadata":{},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"encoder\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"encoder\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n","<span style=\"font-weight: bold\"> Layer (type)        </span><span style=\"font-weight: bold\"> Output Shape      </span><span style=\"font-weight: bold\">    Param # </span><span style=\"font-weight: bold\"> Connected to      </span>\n","\n"," input_layer          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n","\n"," conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,            <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>  input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n","                      <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                                              \n","\n"," conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span>  conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      \n","\n"," flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3136</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n","\n"," dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">50,192</span>  flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n","\n"," mean (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>  dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n","\n"," z_log_var (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>  dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n","\n"," sigma (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  z_log_var[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n","\n"," sampling (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  mean[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       \n","                                                     z_log_var[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n","\n"," multiply_3           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  sigma[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)                                          sampling[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n","\n"," add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  mean[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       \n","                                                     multiply_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n","\n","</pre>\n"],"text/plain":["\n","\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m\n","\n"," input_layer          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)           \u001b[38;5;34m0\u001b[0m  -                 \n"," (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n","\n"," conv2d (\u001b[38;5;33mConv2D\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,            \u001b[38;5;34m320\u001b[0m  input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] \n","                      \u001b[38;5;34m32\u001b[0m)                                              \n","\n"," conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)       \u001b[38;5;34m18,496\u001b[0m  conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      \n","\n"," flatten (\u001b[38;5;33mFlatten\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3136\u001b[0m)                \u001b[38;5;34m0\u001b[0m  conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n","\n"," dense (\u001b[38;5;33mDense\u001b[0m)        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             \u001b[38;5;34m50,192\u001b[0m  flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n","\n"," mean (\u001b[38;5;33mDense\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                  \u001b[38;5;34m34\u001b[0m  dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n","\n"," z_log_var (\u001b[38;5;33mDense\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                  \u001b[38;5;34m34\u001b[0m  dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n","\n"," sigma (\u001b[38;5;33mLambda\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   \u001b[38;5;34m0\u001b[0m  z_log_var[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n","\n"," sampling (\u001b[38;5;33mLambda\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   \u001b[38;5;34m0\u001b[0m  mean[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       \n","                                                     z_log_var[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n","\n"," multiply_3           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   \u001b[38;5;34m0\u001b[0m  sigma[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      \n"," (\u001b[38;5;33mMultiply\u001b[0m)                                          sampling[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n","\n"," add (\u001b[38;5;33mAdd\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   \u001b[38;5;34m0\u001b[0m  mean[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       \n","                                                     multiply_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n","\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">69,076</span> (269.83 KB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m69,076\u001b[0m (269.83 KB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">69,076</span> (269.83 KB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m69,076\u001b[0m (269.83 KB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"}],"source":["encoder = Model(encoder_input, outputs = [mean, log_var, z], name = 'encoder')\n","encoder.summary()"]},{"cell_type":"markdown","id":"d034e021-03ba-4e46-9c5c-3d10c8536847","metadata":{},"source":["## Decoder Part\n","\n","The decoder part of a VAE is the same as that of a regular Autoencoder. To upsample the output from the encoder, we can use the Keras Sequential model API to group a stack of Dense layers and Transpose Convolution layers together.\n","\n","<center>\n","    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML311-Coursera/labs/decoder.png\" width=\"400\" alt=\"computer components\"  />\n","<center>\n"]},{"cell_type":"code","execution_count":24,"id":"c3f011a8-4edf-4997-b826-58e66e533b8b","metadata":{},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"sequential_1\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n","<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n","\n"," dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3136</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">9,408</span> \n","\n"," reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n","\n"," conv2d_transpose_3               (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)                                                      \n","\n"," conv2d_transpose_4               (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">18,464</span> \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)                                                      \n","\n"," conv2d_transpose_5               (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">289</span> \n"," (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)                                                      \n","\n","</pre>\n"],"text/plain":["\n","\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n","\n"," dense_2 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3136\u001b[0m)                    \u001b[38;5;34m9,408\u001b[0m \n","\n"," reshape_1 (\u001b[38;5;33mReshape\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)                    \u001b[38;5;34m0\u001b[0m \n","\n"," conv2d_transpose_3               (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)             \u001b[38;5;34m36,928\u001b[0m \n"," (\u001b[38;5;33mConv2DTranspose\u001b[0m)                                                      \n","\n"," conv2d_transpose_4               (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)             \u001b[38;5;34m18,464\u001b[0m \n"," (\u001b[38;5;33mConv2DTranspose\u001b[0m)                                                      \n","\n"," conv2d_transpose_5               (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 \u001b[38;5;34m289\u001b[0m \n"," (\u001b[38;5;33mConv2DTranspose\u001b[0m)                                                      \n","\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">65,089</span> (254.25 KB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m65,089\u001b[0m (254.25 KB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">65,089</span> (254.25 KB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m65,089\u001b[0m (254.25 KB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"}],"source":["latent_dim=2\n","decoder=Sequential()\n","\n","decoder.add(keras.Input(shape=(latent_dim,))) # input dimension is 2\n","decoder.add(Dense(7 * 7 * 64, activation=\"relu\"))\n","decoder.add(Reshape((7, 7, 64)))\n","decoder.add(Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\"))\n","decoder.add(Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\"))\n","decoder.add(Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\"))\n","decoder.summary()"]},{"cell_type":"markdown","id":"b84d9457-49a8-4bcd-8676-3996ff2fde4e","metadata":{},"source":["## Loss Function\n"]},{"cell_type":"markdown","id":"110c4b5a-56d5-4912-8b26-8e12b24cb004","metadata":{},"source":["We include the **reconstruction loss**, which compares the output of the VAE to the original input. In this case, we use the mean square error. We also include a **regularization term**, which regularizes the organization of the latent space by making the distribution learned by the encoder close to a standard normal distribution. The regularization is enforced using the KullbackLeibler divergence that compares two distributions.\n"]},{"cell_type":"code","execution_count":25,"id":"067da211-a02c-4317-853d-fcaf9542bc67","metadata":{},"outputs":[],"source":["# make loss function \n","\n","#reconstruction_loss\n","def reconstruction_loss(y, y_hat):\n","    return tf.reduce_mean(tf.square(y - y_hat))\n","\n","\n","#KullbackLeibler divergence encoder loss\n","def kl_loss(mu, log_var):\n","    loss = -0.5 * tf.reduce_mean(1 + log_var - tf.square(mean) - tf.exp(log_var))\n","    return loss\n","\n","# add two losses \n","def vae_loss(y_true, y_hat, mu, log_var):\n","    return reconstruction_loss(y_true, y_hat) + (1 / (64*64)) * kl_loss(mean, log_var)\n"]},{"cell_type":"markdown","id":"f0a1e2be-5d16-497d-b5c5-df25567c5690","metadata":{},"source":["## Putting it all Together\n"]},{"cell_type":"markdown","id":"d0ff94ad-4ae0-4917-bd1d-d22c7a485764","metadata":{},"source":["We combine the Encoder and Decoder to create a VAE, and append the regularization term to the model:\n"]},{"cell_type":"code","execution_count":26,"id":"abe7e78c-8d2a-493a-aa9b-077253d3faae","metadata":{},"outputs":[{"ename":"ValueError","evalue":"A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[26], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m reconstructed \u001b[38;5;241m=\u001b[39m decoder(z)\n\u001b[0;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(encoder_input, reconstructed, name \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvae\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mkl_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_var\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39madd_loss(loss)\n\u001b[0;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n","Cell \u001b[1;32mIn[25], line 10\u001b[0m, in \u001b[0;36mkl_loss\u001b[1;34m(mu, log_var)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mkl_loss\u001b[39m(mu, log_var):\n\u001b[1;32m---> 10\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_mean(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m log_var \u001b[38;5;241m-\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msquare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m tf\u001b[38;5;241m.\u001b[39mexp(log_var))\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n","File \u001b[1;32mc:\\GitHub\\IBM_Machine_Learning\\venv\\Lib\\site-packages\\tensorflow\\python\\ops\\weak_tensor_ops.py:88\u001b[0m, in \u001b[0;36mweak_tensor_unary_op_wrapper.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     87\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     90\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n","File \u001b[1;32mc:\\GitHub\\IBM_Machine_Learning\\venv\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:13363\u001b[0m, in \u001b[0;36msquare\u001b[1;34m(x, name)\u001b[0m\n\u001b[0;32m  13361\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m _result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[0;32m  13362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m> 13363\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msquare_eager_fallback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  13364\u001b[0m \u001b[43m      \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_ctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  13365\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_SymbolicException:\n\u001b[0;32m  13366\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n","File \u001b[1;32mc:\\GitHub\\IBM_Machine_Learning\\venv\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:13404\u001b[0m, in \u001b[0;36msquare_eager_fallback\u001b[1;34m(x, name, ctx)\u001b[0m\n\u001b[0;32m  13403\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msquare_eager_fallback\u001b[39m(x: Annotated[Any, TV_Square_T], name, ctx) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Annotated[Any, TV_Square_T]:\n\u001b[1;32m> 13404\u001b[0m   _attr_T, (x,) \u001b[38;5;241m=\u001b[39m \u001b[43m_execute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs_to_matching_eager\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m_dtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_dtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhalf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_dtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_dtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_dtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint8\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_dtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint16\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_dtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_dtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_dtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_dtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint16\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_dtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_dtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_dtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomplex64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_dtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomplex128\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  13405\u001b[0m   _inputs_flat \u001b[38;5;241m=\u001b[39m [x]\n\u001b[0;32m  13406\u001b[0m   _attrs \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m\"\u001b[39m, _attr_T)\n","File \u001b[1;32mc:\\GitHub\\IBM_Machine_Learning\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:251\u001b[0m, in \u001b[0;36margs_to_matching_eager\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;66;03m# First see if we can get a valid dtype with the default conversion\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# and see if it matches an allowed dtypes. Some ops like ConcatV2 may\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# not list allowed dtypes, in which case we should skip this.\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m allowed_dtypes:\n\u001b[1;32m--> 251\u001b[0m   tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtensor_conversion_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m   \u001b[38;5;66;03m# If we did not match an allowed dtype, try again with the default\u001b[39;00m\n\u001b[0;32m    253\u001b[0m   \u001b[38;5;66;03m# dtype. This could be because we have an empty tensor and thus we\u001b[39;00m\n\u001b[0;32m    254\u001b[0m   \u001b[38;5;66;03m# picked the wrong type.\u001b[39;00m\n\u001b[0;32m    255\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_dtypes:\n","File \u001b[1;32mc:\\GitHub\\IBM_Machine_Learning\\venv\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py:209\u001b[0m, in \u001b[0;36mconvert\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[0;32m    207\u001b[0m overload \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(value, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__tf_tensor__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m overload \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 209\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moverload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m#  pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m base_type, conversion_func \u001b[38;5;129;01min\u001b[39;00m get(\u001b[38;5;28mtype\u001b[39m(value)):\n\u001b[0;32m    212\u001b[0m   \u001b[38;5;66;03m# If dtype is None but preferred_dtype is not None, we try to\u001b[39;00m\n\u001b[0;32m    213\u001b[0m   \u001b[38;5;66;03m# cast to preferred_dtype first.\u001b[39;00m\n\u001b[0;32m    214\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[1;32mc:\\GitHub\\IBM_Machine_Learning\\venv\\Lib\\site-packages\\keras\\src\\backend\\common\\keras_tensor.py:138\u001b[0m, in \u001b[0;36mKerasTensor.__tf_tensor__\u001b[1;34m(self, dtype, name)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__tf_tensor__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 138\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    139\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA KerasTensor cannot be used as input to a TensorFlow function. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    140\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA KerasTensor is a symbolic placeholder for a shape and dtype, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    141\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mused when constructing Keras Functional models \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor Keras Functions. You can only use it as input to a Keras layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor a Keras operation (from the namespaces `keras.layers` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    144\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand `keras.operations`). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are likely doing something like:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    146\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    147\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = Input(...)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf_fn(x)  # Invalid.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    150\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    151\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat you should do instead is wrap `tf_fn` in a layer:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    152\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    153\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass MyLayer(Layer):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    154\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def call(self, x):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    155\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return tf_fn(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = MyLayer()(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    158\u001b[0m     )\n","\u001b[1;31mValueError\u001b[0m: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n"]}],"source":["# encoder returns mean and log variance of the normal distribution,\n","# and a sample point z\n","mean, log_var, z = encoder(encoder_input)\n","\n","# decoder decodes the sample z \n","reconstructed = decoder(z)\n","\n","model = Model(encoder_input, reconstructed, name =\"vae\")\n","loss = kl_loss(mean, log_var)\n","model.add_loss(loss)\n","model.summary()"]},{"cell_type":"markdown","id":"b35378b1-350c-4e2e-9ba2-6fa5c26fbf63","metadata":{},"source":["## Training the VAE\n","\n","We now train the model. After each epoch, we input random noise <code>z</code> into the decoder. We will see for each epoch, the decoder output will look more and more like a digit.\n","\n","We also output the values for the latent space z for all the different digits in our dataset, color coded according to class. We see that for each iteration, the samples appeared more clustered.\n"]},{"cell_type":"code","execution_count":null,"id":"70dace1c-04f3-452c-9105-b34a77df8a84","metadata":{},"outputs":[],"source":["#loss\n","mse_losses = []\n","kl_losses = []\n","# optimizer \n","optimizer =  tf.keras.optimizers.Adam(learning_rate = 0.0002, beta_1 = 0.5, beta_2 = 0.999 )\n","epochs = 5\n","\n","for epoch in range(epochs):\n","    \n","    print(f\"Samples generated by decoder after {epoch} epoch(s): \")\n","    \n","    #random noise\n","    z = tf.random.normal(shape = (5, latent_dim,))\n","\n","    # input random noise into the decoder\n","    xhat = decoder.predict(z)\n","    \n","    # plot the decoder output\n","    plt.figure()\n","    for i in range(5):\n","        plt.subplot(1,5,i+1)\n","        plt.imshow(xhat[i,:,:,0],cmap=\"gray\")\n","        plt.axis(\"off\")\n","    plt.show()\n","\n","    print(f\"2D latent representations of the training data produced by encoder after {epoch} epoch(s): \")\n","    plot_label_clusters(encoder, X_train, y_train)\n","\n","\n","    # training steps\n","    for (step, training_batch) in enumerate(dataset.batch(100)):\n","        with tf.GradientTape() as tape:\n","\n","            # model output\n","            reconstructed = model(training_batch)\n","\n","            y_true = tf.reshape(training_batch, shape = [-1])\n","            y_pred = tf.reshape(reconstructed, shape = [-1])\n","\n","            # calculate reconstruction loss\n","            mse_loss = reconstruction_loss(y_true, y_pred)\n","            # calculate KL divergence\n","            kl = sum(model.losses)\n","\n","            kl_losses.append(kl.numpy())\n","            mse_losses.append(mse_loss .numpy())\n","\n","            # total loss\n","            train_loss = 0.01 * kl + mse_loss\n","\n","            grads = tape.gradient(train_loss, model.trainable_variables)\n","            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n","         \n","    print(\"Epoch: %s - Step: %s - MSE loss: %s - KL loss: %s\" % (epoch, step, mse_loss.numpy(), kl.numpy()))\n","  "]},{"cell_type":"markdown","id":"241e34b5-3542-45ad-8a6a-1d4c400578b8","metadata":{},"source":["We plot the reconstruction loss and KullbackLeibler divergence against the number of training iterations, we can see that they are both decreasing.\n"]},{"cell_type":"code","execution_count":null,"id":"2bdbe889-a48f-4cfd-8fce-2738baba965d","metadata":{},"outputs":[],"source":["plt.plot(mse_losses)\n","plt.title(\" reconstruction loss \")\n","plt.show()\n","plt.plot(kl_losses)\n","plt.title(\"  KullbackLeibler divergence\")\n","plt.show()"]},{"cell_type":"markdown","id":"4780e779-b906-4d2a-a0d4-aae036cc42d0","metadata":{},"source":["Now that our VAE has been trained, we can use its decoder network to generate some samples. Let's see if our decoder can do a good job in generating artificial images that look like digits!\n"]},{"cell_type":"code","execution_count":null,"id":"269cf7b5-c018-40ed-926d-99e477c3dc44","metadata":{},"outputs":[],"source":["xhat = decoder.predict(z)\n","\n","for i in range(5):\n","    plt.imshow(xhat[i,:,:,0],cmap=\"gray\")\n","    plt.show()"]},{"cell_type":"markdown","id":"72b8e4ff-3f29-4f95-adf5-4803de0588f7","metadata":{},"source":["We can also visualize the final latent representations of the training data produced by the trained encoder on a 2D plot, colored by classes.\n"]},{"cell_type":"code","execution_count":null,"id":"5be02030-6998-4135-a9f8-6a93c8f0a5a7","metadata":{},"outputs":[],"source":["plot_label_clusters(encoder, X_train, y_train)"]},{"cell_type":"markdown","id":"2c2b8b71-30f4-43c8-8ac3-7a34fe471717","metadata":{},"source":["## Congratulations! You have completed this lab.\n"]},{"cell_type":"markdown","id":"46bd6d48-9415-48d1-ba59-93cdcc1e55a5","metadata":{},"source":["## Authors\n"]},{"cell_type":"markdown","id":"8ef5302f-ffa6-494d-b2c1-c29da21cd914","metadata":{},"source":["[Joseph Santarcangelo](https://www.linkedin.com/in/joseph-s-50398b136/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML311Coursera35714171-2022-01-01) has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD.\n","\n","[Roxanne Li](https://www.linkedin.com/in/roxanne-li/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML311Coursera35714171-2022-01-01) is a Data Science intern at IBM Skills Network, entering level-5 study in the Mathematics & Statistics undergraduate Coop program at McMaster University.\n"]},{"cell_type":"markdown","id":"157485b9-243a-4b6c-b641-e7f81d1e7ab0","metadata":{},"source":["## Change Log\n"]},{"cell_type":"markdown","id":"c9eacc5b-1e3e-41e0-ab5f-784efa08fc2d","metadata":{},"source":["| Date (YYYY-MM-DD) | Version | Changed By | Change Description      |\n","| ----------------- | ------- | ---------- | ----------------------- |\n","| 2022-09-14        | 0.1     | Joseph S.  | Created Lab             |\n","| 2022-09-19        | 0.1     | Roxanne Li | Reviewed and edited lab |\n"]},{"cell_type":"markdown","id":"7c148313-a18c-4490-b70a-184c0975ba74","metadata":{},"source":["Copyright  2022 IBM Corporation. All rights reserved.\n"]}],"metadata":{"kernelspec":{"display_name":"venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":4}
