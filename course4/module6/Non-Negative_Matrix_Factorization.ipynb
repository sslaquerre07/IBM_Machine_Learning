{"cells":[{"cell_type":"markdown","metadata":{},"source":["<center>\n","    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"300\" alt=\"cognitiveclass.ai logo\">\n","</center>\n"]},{"cell_type":"markdown","metadata":{},"source":["# Non-Negative Matrix Factorization\n","\n","Estimated time needed: **45** minutes\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","You've been hired by a video streaming platform that specializes in kids content. The company would like to ensure that all content on the platform does not infringe on a copyright written material. The company has created an image database of copyrighted material, not only must you detect the same images you must detect similar images. Your  job is to come up with an image retrieval system to find the most similar image to each image in the provided dataset. Because your model is used for legal purposes it must be interpretable, this means it should be able to determine why the images are similar. As a result, you will use Non-Negative Matrix factorization since the factorized matrices can be interpreted as real images. You will use the [Anime Face Dataset](https://www.kaggle.com/datasets/splcher/animefacedataset?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01) from kaggle.\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%203/images/fake_cartoon.png\" alt=\"cognitiveclass.ai logo\">\n","\n","<a href=\"https://www.piratesandprincesses.net/the-story-of-goodtimes-and-their-numerous-disney-knockoffs/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01\"> image source</a>\n"]},{"cell_type":"markdown","metadata":{"tags":[]},"source":["## Table of Contents\n","\n","<ol>\n","    <li><a href=\"#Objectives\">Objectives</a></li>\n","    <li><a href=\"#Datasets\">Datasets</a></li>\n","    <li>\n","        <a href=\"#Setup\">Setup</a>\n","        <ol>\n","            <li><a href=\"#Installing-Required-Libraries\">Installing Required Libraries</a></li>\n","            <li><a href=\"#Importing-Required-Libraries\">Importing Required Libraries</a></li>\n","            <li><a href=\"#Defining-Helper-Functions\">Defining Helper Functions</a></li>\n","        </ol>\n","    </li>\n","    <li>\n","        <a href=\"#Background\">Background</a>\n","        <ol>\n","               <li><a href=\"#What's a Non-Negative Matrix Fatorization?\">What's a Non-Negative Matrix Fatorization?</a></li>\n","        </ol>\n","    </li>\n","  <li><a href=\"#Applying Non-Negative Matrix Factorization\">Applying Non-Negative Matrix Factorization</a></li>\n","  <li><a href=\"#Image Retrieval System\">Image Retrieval System</a></li>\n","   <li><a href=\"#Exercises\">Exercises</a>\n","       <ol>\n","            <li><a href=\"#Exercise 1\">Exercise 1</a></li>\n","            <li><a href=\"#Exercise 2\">Exercise 2</a></li>\n","            <li><a href=\"#Exercise 3\">Exercise 3</a></li>\n","            <li><a href=\"#Exercise 4\">Exercise 4</a></li>\n","            <li><a href=\"#Exercise 5\">Exercise 5</a></li>\n","        </ol>\n","    </li> \n"," </ol>    \n","     \n","    \n","     \n","\n","## Objectives\n","\n","After completing this lab you will be able to:\n","\n","- __Understand__ Basics Matrix operations  such as Matrix addition  , Vector Multiplicationï¼Œand Eigen decomposition\n","\n","- __Apply__ Apply these Matrix operations using numpy\n"]},{"cell_type":"markdown","metadata":{},"source":["***\n"]},{"cell_type":"markdown","metadata":{"tags":[]},"source":["## Datasets\n","\n","Download and unzip the **images** dataset: \n"]},{"cell_type":"markdown","metadata":{"tags":[]},"source":["## Setup\n"]},{"cell_type":"markdown","metadata":{},"source":["For this lab, we will be using the following libraries:\n","\n","*   [`pandas`](https://pandas.pydata.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML240ENSkillsNetwork34171862-2022-01-01) for managing the data.\n","*   [`numpy`](https://numpy.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML240ENSkillsNetwork34171862-2022-01-01) for mathematical operations.\n","*   [`seaborn`](https://seaborn.pydata.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML240ENSkillsNetwork34171862-2022-01-01) for visualizing the data.\n","*   [`matplotlib`](https://matplotlib.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML240ENSkillsNetwork34171862-2022-01-01) for visualizing the data.\n","*   [`sklearn`](https://scikit-learn.org/stable/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML240ENSkillsNetwork34171862-2022-01-01) for machine learning and machine-learning-pipeline related functions.\n"]},{"cell_type":"markdown","metadata":{},"source":["### Installing required libraries\n"]},{"cell_type":"markdown","metadata":{},"source":["The following required modules are pre-installed in the Skills Network Labs environment. However, if you run this notebook commands in a different Jupyter environment (e.g. Watson Studio or Ananconda) you will need to install these libraries by removing the `#` sign before `!mamba` in the code cell below.\n"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["# All Libraries required for this lab are listed below. The libraries pre-installed on Skills Network Labs are commented.\n","# !mamba install -qy pandas==1.3.4 numpy==1.21.4 seaborn==0.9.0 matplotlib==3.5.0 scikit-learn==0.20.1\n","# Note: If your environment doesn't support \"!mamba install\", use \"!pip install\"\n"]},{"cell_type":"markdown","metadata":{},"source":["you can use  <a href=\"https://www.sympy.org/en/index.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01\">SymPy </a>this to print matrices \n"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["#!conda install -c anaconda sympy -y"]},{"cell_type":"markdown","metadata":{"tags":[]},"source":["### Importing Required Libraries\n","\n","_We recommend you import all required libraries in one place (here):_\n"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["import warnings\n","warnings.simplefilter('ignore')\n","\n","import logging\n","import numpy as np\n","import pandas as pd\n","from numpy.random import RandomState\n","import matplotlib.pyplot as plt\n","\n","\n","from sklearn.decomposition import NMF\n","\n","\n","from os import listdir,getcwd\n","from os.path import isfile, join\n","from PIL import Image, ImageOps\n","import os \n"]},{"cell_type":"markdown","metadata":{"tags":[]},"source":["### Defining Helper Functions\n"]},{"cell_type":"markdown","metadata":{},"source":["Load train and test set:\n"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["def get_data_matrix(test=False,Length=100,Width=100,mypath=\"images/\"):\n","\n","    import os\n","import numpy as np\n","from PIL import Image, ImageOps\n","\n","def get_data_matrix(test=False, Length=100, Width=100, mypath=\"images/\"):\n","    files = []\n","    for root, _, filenames in os.walk(mypath):\n","        for f in filenames:\n","            if isfile(join(root, f)) and f[0] != '.':\n","                files.append(join(root, f))\n","    \n","    # Remove .DS_Store files if present\n","    files = [f for f in files if '.DS_Store' not in f]\n","\n","    # Split into test or training data\n","    if test:\n","        print(\"test data\")\n","        files = files[9000:10000]\n","    else:\n","        print(\"training data\")\n","        files = files[0:9000]\n","\n","    print(len(files))\n","\n","    X = np.zeros((len(files), Length * Width))\n","    for i, file in enumerate(files):\n","        img = Image.open(file).resize((Width, Length))\n","        img = ImageOps.grayscale(img)\n","        I = np.array(img)\n","        X[i, :] = I.reshape(1, -1)\n","\n","    return X\n"]},{"cell_type":"markdown","metadata":{},"source":["Plot image vectors:\n"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["def reshape_row(x) :\n","    plt.imshow(x.reshape(Length,Width),cmap=\"gray\")\n","    "]},{"cell_type":"markdown","metadata":{},"source":["This threshold function outputs an index if the input ```similar_distance``` is grater than or less than ```min_``` and ```max_```.\n"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["def threshold(similar_distance,max_=0.1,min_=0):\n","    dataset_index=np.where(np.logical_and(similar_distance>min_ ,similar_distance<max_))[0]\n","    query_index=similar_index[np.logical_and(similar_distance>min_ ,similar_distance<max_)]\n","    return dataset_index,query_index"]},{"cell_type":"markdown","metadata":{},"source":["Plot dataset images and query images, ```X``` and ```X_q``` are global variables.\n"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["def plot_data_query(dataset_index,query_index,N):\n","    for data_sample,query_sample in zip(dataset_index[0:N],query_index[0:N]):\n","\n","        plt.figure(figsize=(10,4))\n","        plt.subplot(1,2,1)\n","        reshape_row(X[data_sample])\n","        plt.title(\"dataset sample {}\".format(data_sample))\n","        plt.subplot(1,2,2)\n","        reshape_row(X_q[query_sample])\n","        plt.title(\"query sample match {}\".format(query_sample))\n","        plt.show()\n","\n","        print(\"-----------------------------------------------------\")"]},{"cell_type":"markdown","metadata":{},"source":["## Background\n"]},{"cell_type":"markdown","metadata":{},"source":["### What's a Non-Negative Matrix Factorization?\n"]},{"cell_type":"markdown","metadata":{},"source":["In Non-Negative Matrix Factorization (NNMF) sometimes called non-negative matrix approximation, a $N x D$ matrix $\\mathbf{X}$, where $N$ is the number of samples and $D$ is the dimension of features, contains all non-negative values. In NNMF we construct a non-negative  approximation of $\\mathbf{X}$, $\\mathbf{\\hat{X}}$ such that $\\mathbf{\\hat{X}}$ is a product of two non-negative matrices $\\mathbf{W}$ and $\\mathbf{H}$, i.e:\n","\n","$$\\mathbf{\\hat{X}}=\\mathbf{WH}$$\n","\n","where the $r$ rows of $\\mathbf{H}$ are called the basis, and we are going to represent the matrix $\\mathbf{X}$ in terms of this basis. \n","\n","Each row of $\\mathbf{W}$, ${w}_i$ is called an encoding of the corresponding ${x}_i$ in $\\mathbf{X}$, which represents \"how much\" of each basis in $\\mathbf{H}$ is to represent ${x}_i$. ${\\hat{x}_i}$ is thus a linear combination of the rows of $\\mathbf{H}$.\n"]},{"cell_type":"markdown","metadata":{},"source":["## Applying Non-Negative Matrix Factorization\n"]},{"cell_type":"markdown","metadata":{},"source":["**Image retrieval** is used for searching and retrieving images from a large database of digital images. Here we would like to find identical or similar  animated faces  for copyright reasons.\n"]},{"cell_type":"markdown","metadata":{},"source":["Consider the matrix $\\mathbf{X}$ where each row is a flattened $100\\times 100$ image.\n"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m Length,Width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m100\u001b[39m\n\u001b[1;32m----> 2\u001b[0m X\u001b[38;5;241m=\u001b[39m\u001b[43mget_data_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mLength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mWidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmypath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimages/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m X\n","Cell \u001b[1;32mIn[18], line 11\u001b[0m, in \u001b[0;36mget_data_matrix\u001b[1;34m(test, Length, Width, mypath)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m root, _, filenames \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mwalk(mypath):\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m filenames:\n\u001b[1;32m---> 11\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43misfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m f[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     12\u001b[0m             files\u001b[38;5;241m.\u001b[39mappend(join(root, f))\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Remove .DS_Store files if present\u001b[39;00m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["Length,Width=100,100\n","X=get_data_matrix(test=False,Length=100,Width=100,mypath=\"images/\")\n","X"]},{"cell_type":"markdown","metadata":{},"source":["We can apply ```sklearn.decomposition.NMF``` to obtain the  non-negative matrices, i.e. matrices with all non-negative elements, $(\\mathbf{W}$, $\\mathbf{H})$ whose product approximates the non-negative matrix $\\mathbf{X}$. \n","\n","Consider the following parameters when building a simple NMF object: \n","\n","```n_components```: int; Number of components, if n_components is not set all features are kept.\n","\n","```tolfloat```: default=1e-4; Tolerance of the stopping condition.\n","\n","```max_iter```: int, (default=200); Maximum number of iterations before timing out.\n"]},{"cell_type":"markdown","metadata":{},"source":["Let's select a number of components or basis, namely $r$, for the matrix representation.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["n_components=10"]},{"cell_type":"markdown","metadata":{},"source":["Initialize our NMF object and fit it to $\\mathbf{X}$:\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"Found array with 0 sample(s) (shape=(0, 10000)) while a minimum of 1 is required by NMF.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m nmf_estimator \u001b[38;5;241m=\u001b[39m NMF(n_components\u001b[38;5;241m=\u001b[39mn_components, tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-3\u001b[39m,max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2000\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mnmf_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# original non- negative dataset\u001b[39;00m\n","File \u001b[1;32mc:\\GitHub\\IBM_Machine_Learning\\venv\\Lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1311\u001b[0m, in \u001b[0;36m_BaseNMF.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1289\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Learn a NMF model for the data X.\u001b[39;00m\n\u001b[0;32m   1290\u001b[0m \n\u001b[0;32m   1291\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1307\u001b[0m \u001b[38;5;124;03m    Returns the instance itself.\u001b[39;00m\n\u001b[0;32m   1308\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1309\u001b[0m \u001b[38;5;66;03m# param validation is done in fit_transform\u001b[39;00m\n\u001b[1;32m-> 1311\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n","File \u001b[1;32mc:\\GitHub\\IBM_Machine_Learning\\venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 313\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    315\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    316\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    318\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    319\u001b[0m         )\n","File \u001b[1;32mc:\\GitHub\\IBM_Machine_Learning\\venv\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\GitHub\\IBM_Machine_Learning\\venv\\Lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1650\u001b[0m, in \u001b[0;36mNMF.fit_transform\u001b[1;34m(self, X, y, W, H)\u001b[0m\n\u001b[0;32m   1622\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1623\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, W\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, H\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1624\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Learn a NMF model for the data X and returns the transformed data.\u001b[39;00m\n\u001b[0;32m   1625\u001b[0m \n\u001b[0;32m   1626\u001b[0m \u001b[38;5;124;03m    This is more efficient than calling fit followed by transform.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1648\u001b[0m \u001b[38;5;124;03m        Transformed data.\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1650\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1651\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   1652\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(assume_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1655\u001b[0m         W, H, n_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_transform(X, W\u001b[38;5;241m=\u001b[39mW, H\u001b[38;5;241m=\u001b[39mH)\n","File \u001b[1;32mc:\\GitHub\\IBM_Machine_Learning\\venv\\Lib\\site-packages\\sklearn\\base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n","File \u001b[1;32mc:\\GitHub\\IBM_Machine_Learning\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1087\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1085\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[1;32m-> 1087\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1088\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1089\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1090\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[0;32m   1091\u001b[0m         )\n\u001b[0;32m   1093\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1094\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n","\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 10000)) while a minimum of 1 is required by NMF."]}],"source":["nmf_estimator = NMF(n_components=n_components, tol=5e-3,max_iter=2000)\n","nmf_estimator.fit(X)  # original non- negative dataset"]},{"cell_type":"markdown","metadata":{},"source":["The **.components_** method returns the basis found:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["H = nmf_estimator.components_"]},{"cell_type":"markdown","metadata":{},"source":["We can reshape the obtained 10 basis into images, and they appear like faces in the dataset:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.figure(figsize=(25, 8))\n","\n","for i,h in enumerate(H):   \n","    plt.subplot(2, 5, i+1)\n","    reshape_row(h)\n","    plt.title(\"basis images {}\".format(str(i+1)), fontsize=20) \n","    \n","plt.tight_layout()"]},{"cell_type":"markdown","metadata":{},"source":["We can obtain the encodings of all the images using the **transform** method of the fitted **nmf_estimator**:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["W = nmf_estimator.transform(X)"]},{"cell_type":"markdown","metadata":{},"source":["For each of the 9000 images we have an encoding of dimension 10:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["W.shape"]},{"cell_type":"markdown","metadata":{},"source":["The encoding tells you the projection of each image in $\\mathbf{X}$ on a particular basis. Here we plot out the encoding magnitude for the $i$th image on each basis.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["i=0\n","w=W[i,:]\n","\n","plt.bar([n+1 for n in range(len(w))],w)\n","plt.title(\"encodings for image {} \".format (i+1))"]},{"cell_type":"markdown","metadata":{},"source":["We see that for image 1, the second encoding has the highest magnitude, thus we can plot out the basis associated with this encoding (i.e, the second basis) and see that it's very similar to the image. The 9th encoding has a small magnitude, we see the associated basis looks nothing like the image:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.figure(figsize=(15,4))\n","\n","plt.subplot(131)\n","reshape_row(X[i,:])\n","plt.title(\"Original image\")\n","\n","plt.subplot(132)\n","reshape_row(H[1,:])\n","plt.title(\"Similar basis 2\")\n","\n","plt.subplot(133)\n","reshape_row(H[8,:])\n","plt.title(\"Dissimilar basis 9\")"]},{"cell_type":"markdown","metadata":{},"source":["We can perform the inverse transform using the method **inverse_transform** to get $\\mathbf{\\hat{X}}$, the approximation of $\\mathbf{X}$:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["Xhat=nmf_estimator.inverse_transform(W)"]},{"cell_type":"markdown","metadata":{},"source":["Each row of $\\mathbf{\\hat{X}}$ corresponds to an image. We can reshape the row into an image and plot the approximations:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.figure(figsize=(20,8))\n","\n","for i in range(1,5):\n","    plt.subplot(2,4,i)\n","    reshape_row(X[i])\n","    plt.title(f\"Original image {i}\")\n","    \n","    plt.subplot(2,4,i+4)\n","    reshape_row(Xhat[i])\n","    plt.title(f\"Approximated image {i}\")"]},{"cell_type":"markdown","metadata":{},"source":["We can verify that the scikit-learn's **inverse_transform** method essentially performs the following matrix operation:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["Xhat_M=W@H"]},{"cell_type":"markdown","metadata":{},"source":["We see the results are identical quantitatively (for the first 10 grayscale values of first image):\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["Xhat[0,:10], Xhat_M[0,:10]"]},{"cell_type":"markdown","metadata":{},"source":["and qualitatively or visually for the second to fifth image in the dataset: \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.figure(figsize=(20,8))\n","\n","for i in range(1,5):\n","    plt.subplot(2,4,i)\n","    reshape_row(Xhat[i])\n","    plt.title(f\"Approximated image {i} with sklearn\")\n","    \n","    plt.subplot(2,4,i+4)\n","    reshape_row(Xhat_M[i])\n","    plt.title(f\"Approximated image {i} with matrix operation\")"]},{"cell_type":"markdown","metadata":{},"source":["We can reconstruct the image by adding one component multiplied by it's encoding at a time. This is shown in the following lines of code, as each successive component is added we see the image looks more and more like it's approximation:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# initialize an image array with 10000 zeros which will be reshaped as 100x100  \n","image=np.zeros((1,10000))\n","\n","plt.figure(figsize=(25,8))\n","for i, (w_, h) in enumerate(zip(w, H)):\n","    \n","    # w is the encoding vector of the first image in X\n","    # reconstruction of the image is a linear combination of H \n","    plt.subplot(2,5,i+1)\n","    image += w_*h\n","    reshape_row(image)\n","    plt.title(f\"{i+1} components added\", fontsize=20)\n","plt.tight_layout()"]},{"cell_type":"markdown","metadata":{"tags":[]},"source":["## Image Retrieval System \n"]},{"cell_type":"markdown","metadata":{},"source":["An image retrieval system is a system used for browsing, searching and retrieving images from a large database of digital images. In this section we will create an image retrieval system to find similar cartoon characters for copyright infringement. \n","\n","We define the query dataset as the set of 1000 images. If these images are similar to the images in our original dataset, they may be considered as copyright infringement. We load the query dateset into```X_q``` where each row corresponds to a flattened $100\\times 100$ image:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_q=get_data_matrix(test=True,Length=100,Width=100,mypath=\"images\")\n","X_q.shape"]},{"cell_type":"markdown","metadata":{},"source":["The code in the next cell helps us retain much of the important information of the query images and reduces factors that make similar images appear differently such as noise, rotation and scale. In addition, the code results in a matrix `W_q` that requires less computation for calculating the distance metrics. As such we will use the code to find the similar images.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["W_q=nmf_estimator.transform(X_q)\n","W_q.shape"]},{"cell_type":"markdown","metadata":{},"source":["We define  the  distance matrix as a  matrix ```D``` containing the distances, taken pairwise, between the elements of the query dataset and the original dataset.  We will use the cosine similarity that computes the normalized dot product of vectors. That is, for $x$ and $x'$ their cosine similarity  is defined as:\n","\n","$$1-\\frac{x' x^T}{\\|x'\\| \\|x\\|}$$\n"]},{"cell_type":"markdown","metadata":{},"source":["Consider the following set of codes in which case that we represent as 2D vectors.  The original  dataset is in yellow and the query dataset is in blue. We see that the image $h_2$ is nearest  to  $h_{2q}$, and similarly image $h_3$ is nearest  to  $h_{1q}$.\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%203/images/NNMF_vectors.png\" width=\"500\" alt=\"https://pxhere.com/en/photo/1536663\">\n"]},{"cell_type":"markdown","metadata":{},"source":["The resultant distance Matrix is shown below, each row consists of a dataset sample and each column consists of a query dataset sample. Each element of the distance Matrix comprises of the distance between the sample of that particular row and that particular column. We see in this case samples that are close together have the smallest  value. For example, image $h_2$  in the second row is nearest to $h_{2q}$ in the second column.\n"]},{"cell_type":"markdown","metadata":{},"source":["<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%203/images/Sim_Matix.png\" width=\"500\" alt=\"https://pxhere.com/en/photo/1536663\">\n"]},{"cell_type":"markdown","metadata":{},"source":["We will use the function ```pairwise_distances``` from scikit-learn. This method takes either a vector array or a distance matrix, and returns a distance matrix. If the input is a vector array, the distances are computed.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import pairwise_distances"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# calculates the pairwise distance between the NNMF encoded version of \n","# the original dataset W and the encoded version of the query dataset W_q\n","D=pairwise_distances(W,W_q,metric='cosine')"]},{"cell_type":"markdown","metadata":{},"source":["We see the number of rows corresponds to the number of samples in the original dataset and the number of columns  corresponds to the number of samples in the query dateset.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["D.shape"]},{"cell_type":"markdown","metadata":{},"source":["For each sample in the dataset we find the query sample that has the smallest distance to it, which would be the most similar image. As each image in the original dataset corresponds to a row in the distance matrix, the column index with smallest value corresponds to the index of the closest image in the query dataset.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["similar_index=np.argmin(D, axis=1)"]},{"cell_type":"markdown","metadata":{},"source":["We also find the corresponding distance value \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["similar_distance=np.min(D, axis=1)"]},{"cell_type":"markdown","metadata":{},"source":["We plot out the distance values in a histogram; we see the values range from zero to approximately 0.06.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.hist(similar_distance,bins=100)\n","plt.title(\"Distance values\")"]},{"cell_type":"markdown","metadata":{},"source":["If we try a maximum threshold of $1.0x10^{-5}$ for the distance value for the first five samples, we get identical images\n"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[]},"outputs":[],"source":["dataset_index,query_index=threshold(similar_distance,max_=0.00001,min_=0)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset_index.shape, query_index.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset_index[:10]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["query_index[:10]"]},{"cell_type":"markdown","metadata":{},"source":["If we try a threshold of between $5.0x10^{-3}$ and $1.0x10^{-2}$ instead and plot out the first five samples, it is evident the many of the query images are very different from the original. \n"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[]},"outputs":[],"source":["dataset_index,query_index=threshold(similar_distance,max_=0.005,min_=0.00001)\n","plot_data_query(dataset_index,query_index,5)"]},{"cell_type":"markdown","metadata":{"tags":[]},"source":["## Exercises\n"]},{"cell_type":"markdown","metadata":{},"source":["In this exercise, you will apply NMF on the [face images](https://scikit-learn.org/stable/auto_examples/decomposition/plot_faces_decomposition.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01#sphx-glr-auto-examples-decomposition-plot-faces-decomposition-py) from scikit-learn and perform an image retrievel task to find pairs of faces that are similar.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.datasets import fetch_olivetti_faces\n","\n","rng = RandomState(0)\n","data = fetch_olivetti_faces(shuffle=True, random_state=rng)\n","X = data.images"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[]},"outputs":[],"source":["image_shape = (64, 64)\n","\n","def plot_faces(title, images, n_col, n_row, cmap=plt.cm.gray):\n","    fig, axs = plt.subplots(\n","        nrows = n_row,\n","        ncols = n_col,\n","        figsize = (2.0*n_col, 2.3*n_row),\n","        facecolor='white',\n","        constrained_layout=True)\n","    \n","    fig.set_constrained_layout_pads(w_pad=0.01, h_pad=0.02, hspace=0, wspace=0)\n","    fig.set_edgecolor(\"black\")\n","    fig.suptitle(title, size=16)\n","    for ax, vec in zip(axs.flat, images):\n","        vmax = max(vec.max(), -vec.min())\n","        im = ax.imshow(\n","            vec.reshape(image_shape),\n","            cmap=cmap,\n","            interpolation=\"nearest\",\n","            vmin=-vmax,\n","            vmax=vmax)\n","        ax.axis('off')\n","    \n","    fig.colorbar(im, ax=axs, orientation='horizontal', shrink=0.99, \n","                aspect=40, pad=0.01)\n","    plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["We use the **plot_faces** function to plot the first 6 faces in the dataset.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_faces(\"6 Faces from the Original Dataset\", X[:6], 3, 2)"]},{"cell_type":"markdown","metadata":{"tags":[]},"source":["### Exercise 1\n","\n","Split the dataset into two such that the first 300 is used as the original dataset **X_r** and the remaining 100 is used as the query dataset **X_q**. Initialize a NMF instance with n_components = 10, and use it to transform **X_r** and **X_q** into encodings.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_r = X[:300].reshape((300, 64*64))\n","X_q = X[300:].reshape((100, 64*64))\n","\n","nmf = NMF(n_components=10, tol=5e-3,max_iter=2000)\n","X_r_W = nmf.fit_transform(X_r)\n","X_q_W = nmf.fit_transform(X_q)"]},{"cell_type":"markdown","metadata":{},"source":["<details>\n","    <summary>Click here for Solution</summary>\n","\n","```python\n","nmf = NMF(n_components=6, tol=5e-3,max_iter=2000)\n","nmf.fit(X)\n","```\n","\n","</details>\n"]},{"cell_type":"markdown","metadata":{"tags":[]},"source":["### Exercise 2\n","\n","Calculate the pairwise distances between face encodings from the original and query dataset, store the result in **D**.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[]},"outputs":[],"source":["from sklearn.metrics import pairwise_distances\n","\n","D = pairwise_distances(X_r_W, X_q_W, metric='cosine')"]},{"cell_type":"markdown","metadata":{},"source":["<details>\n","    <summary>Click here for Solution</summary>\n","\n","```python\n","H = nmf.components_\n","plot_faces(\"Basis from dataset\", H, 3, 2)\n","```\n","\n","</details>\n"]},{"cell_type":"markdown","metadata":{"tags":[]},"source":["### Exercise 3\n","\n","For all rows in the pairwise distance matrix, output their smallest distances as **similar_distance**, and the index associated with the smallest distances as **similar_index**.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[]},"outputs":[],"source":["similar_index = np.argmin(D, axis=1)\n","similar_distance = np.min(D, axis=1)"]},{"cell_type":"markdown","metadata":{},"source":["<details>\n","    <summary>Click here for Solution</summary>\n","\n","```python\n","W = nmf.transform(X)\n","w6 = W[:6, :] # picking the first 6 encodings\n","\n","X_hat = nmf.inverse_transform(w6)\n","plot_faces(\"6 Reconstructed faces using inverse_transform\", X_hat, 3, 2)\n","\n","```\n","\n","</details>\n"]},{"cell_type":"markdown","metadata":{"tags":[]},"source":["### Exercise 4\n","\n","Use the **similar_distance** as input for the **threshold** function. You can specify the min and max threshold for the distances. Return the index of the original dataset and the query dataset that satisfy the specified threshold. Use **plot_data_query** to plot the first 5 pairs of face images that our image retrieval system \"views\" as similar.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[]},"outputs":[],"source":["o_index, q_index = threshold(similar_distance)\n","\n","Length=64\n","Width=64\n","plot_data_query(o_index, q_index, 5)"]},{"cell_type":"markdown","metadata":{},"source":["<details>\n","    <summary>Click here for Solution</summary>\n","\n","```python\n","X_hat_M = w6@H\n","plot_faces(\"6 Reconstructed faces using matrix operations\", X_hat_M, 3,2)\n","print(\"-------------------------------------------------------\")\n","plot_faces(\"6 Reconstructed faces using inverse_transform\", X_hat, 3, 2)\n","```\n","\n","</details>\n"]},{"cell_type":"markdown","metadata":{"tags":[]},"source":["# Congratulations! - You have completed the lab\n"]},{"cell_type":"markdown","metadata":{},"source":["## Authors\n"]},{"cell_type":"markdown","metadata":{},"source":["<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2021-01-01\">Joseph Santarcangelo</a> Joseph has a Ph.D. in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD.\n","\n","[Roxanne Li](https://www.linkedin.com/in/roxanne-li/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01) is a Data Science intern at IBM Skills Network, entering level-5 study in the Mathematics & Statistics undergraduate Coop program at McMaster University.\n"]},{"cell_type":"markdown","metadata":{},"source":["## Change Log\n"]},{"cell_type":"markdown","metadata":{},"source":["| Date (YYYY-MM-DD) | Version | Changed By  | Change Description             |\n","| ----------------- | ------- | ----------- | ------------------------------ |\n","| 2022-03-25        | 0.1     | Joseph S.   | Updated all content            |\n","| 2022-04-26        | 0.1     | Svitlana K. | Corrected minor grammar errors |\n","| 2022-06-06        | 0.1     | Roxanne Li  | Review and edit content        |\n"]}],"metadata":{"kernelspec":{"display_name":"venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":4}
