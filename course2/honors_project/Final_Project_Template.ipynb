{"cells":[{"cell_type":"markdown","metadata":{},"source":["<p style=\"text-align:center\">\n","    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01\">\n","    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n","    </a>\n","</p>\n","\n","<h1 align=\"center\"><font size=\"5\">Supervised Machine Learning: Regression - Final Assignment</font></h1>\n"]},{"cell_type":"markdown","metadata":{},"source":["## Instructions:\n","\n","In this Assignment, you will demonstrate the data regression skills you have learned by completing this course. You are expected to leverage a wide variety of tools, but also this report should focus on present findings, insights, and next steps. You may include some visuals from your code output, but this report is intended as a summary of your findings, not as a code review. \n","\n","The grading will center around 5 main points:\n","\n","1. Does the report include a section describing the data?\n","2. Does the report include a paragraph detailing the main objective(s) of this analysis? \n","3. Does the report include a section with variations of linear regression models and specifies which one is the model that best suits the main objective(s) of this analysis.\n","4. Does the report include a clear and well-presented section with key findings related to the main objective(s) of the analysis?\n","5. Does the report highlight possible flaws in the model and a plan of action to revisit this analysis with additional data or different predictive modeling techniques? \n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Import the required libraries\n"]},{"cell_type":"markdown","metadata":{},"source":["The following required modules are pre-installed in the Skills Network Labs environment. However if you run this notebook commands in a different Jupyter environment (e.g. Watson Studio or Ananconda) you will need to install these libraries by removing the `#` sign before `!mamba` in the code cell below.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# All Libraries required for this lab are listed below. The libraries pre-installed on Skills Network Labs are commented.\n","# !mamba install -qy pandas==1.3.4 numpy==1.21.4 seaborn==0.9.0 matplotlib==3.5.0 scikit-learn==0.20.1\n","# Note: If your environment doesn't support \"!mamba install\", use \"!pip install\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from scipy.stats import skew\n","from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score\n","from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n","from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import r2_score\n"]},{"cell_type":"markdown","metadata":{},"source":["## Importing the Dataset\n"]},{"cell_type":"markdown","metadata":{},"source":["Before you begin, you will need to choose a data set that you feel passionate about. You can brainstorm with your peers about great public data sets using the discussion board in this module.\n"]},{"cell_type":"markdown","metadata":{},"source":["Read your chosen dataset into pandas dataframe:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["filepath = \"data/pgafulldata.csv\"\n","data = pd.read_csv(filepath, encoding='latin1')\n","data.head()"]},{"cell_type":"markdown","metadata":{},"source":["Once you have selected a data set, you will produce the deliverables listed below and submit them to one of your peers for review. Treat this exercise as an opportunity to produce analysis that are ready to highlight your analytical skills for a senior audience, for example, the Chief Data Officer, or the Head of Analytics at your company.\n","Sections required in your report:\n","\n","*   Main objective of the analysis that specifies whether your model will be focused on prediction or interpretation.\n","*   Brief description of the data set you chose and a summary of its attributes.\n","*   Brief summary of data exploration and actions taken for data cleaning and feature engineering.\n","*   Summary of training at least three linear regression models which should be variations that cover using a simple  linear regression as a baseline, adding polynomial effects, and using a regularization regression. Preferably, all use the same training and test splits, or the same cross-validation method.\n","*  A paragraph explaining which of your regressions you recommend as a final model that best fits your needs in terms of accuracy and explainability.\n","*  Summary Key Findings and Insights, which walks your reader through the main drivers of your model and insights from your data derived from your linear regression model.\n","*  Suggestions for next steps in analyzing this data, which may include suggesting revisiting this model adding specific data features to achieve a better explanation or a better prediction.\n"]},{"cell_type":"markdown","metadata":{},"source":["# 1. About the Data\n"]},{"cell_type":"markdown","metadata":{},"source":["## Dataset Summary\n","This dataset contains the statistics for the top 200 PGA Tour players from 2015-2019. The original dataset comprises of 29 columns with stats about every aspect of their game, including driving distance, putts per round, proximity to the hole, and many more."]},{"cell_type":"markdown","metadata":{},"source":["## Objective of the Analysis\n","In this analysis of PGA Tour data, the model to be constructed will mostly focus on interpretation. While the model will try and predict Scoring Averages on the testing data, there is more interest on the coefficients that drive those predictions. This will tell us the aspects of the golf game that most directly lead to better scores."]},{"cell_type":"markdown","metadata":{},"source":["## Data Cleaning and Feature Engineering\n","Below are listed all of the actions taken to clean the data and implement new features:\n","- Any row with a null value in the scoring average was removed since that is the target feature\n","- Any distance related metric that was measured in feet and inches was converted to a decimal in feet\n","- This dataset included a lot superfluous statistics that do not relate to performance, so any of those are removed"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Removing any rows without a scoring average (target value)\n","data.dropna(subset=['Scoring Average'], inplace=True)\n","\n","#Seperating the name column into a name and year column\n","def obj_to_int(obj):\n","    if pd.isna(obj):\n","        return None\n","    \n","    return int(obj)\n","\n","data['Player Name'] = data['PLAYER NAME'].str.extract(r'^(.*) \\(\\d{4}\\)$')\n","data['Year'] = data['PLAYER NAME'].str.extract(r'\\((\\d{4})\\)')\n","data['Year'] = data['Year'].apply(obj_to_int)\n","\n","#Function to convert distance to a decimal\n","def feet_inches_string_to_decimal(ft_inches_str):\n","    if pd.isna(ft_inches_str) or ft_inches_str.strip == \"\":\n","        return None\n","    \n","    clean_str = ft_inches_str.replace(\"'\", \"\")\n","    clean_str = clean_str.replace(\"\\\"\", \"\")\n","    parts = clean_str.split(\" \")\n","    if len(parts) != 2:\n","        return None\n","    \n","    height = 0\n","    height += int(parts[0]) + float(int(parts[1])/12)\n","    return height\n","\n","#Convert all feet and inches columns to decimals using the function above\n","data['Decimal Approach from > 100 Yards (Feet)'] = data['Approaches from > 100 yards'].apply(feet_inches_string_to_decimal)\n","data['Average Distance Putts Made (Feet)'] = data['Average Distance of Putts made'].apply(feet_inches_string_to_decimal)\n","data['Decimal Proximity to Hole (Feet)'] = data['Proximity to Hole'].apply(feet_inches_string_to_decimal)\n","    \n","\n","#Removing all unecessary columns\n","data.drop(columns=['Eagles (Holes per)', 'FedexCup Regular Season Points', 'Official Money',\n","                   'Total Birdies', 'Total Eagles', 'Top 10 Finishes', 'Country', 'College', \n","                   'PLAYER NAME', 'Approaches from > 100 yards', 'Average Distance of Putts made',\n","                   'Proximity to Hole', 'Player Name'], inplace=True)\n","\n","#Finally, removing any rows with null values, as there are many rows that are have little to no data\n","data = data.dropna()\n","\n","#Determining skew of the target value and seeing if it needs to be transformed\n","result_score = data['Scoring Average']\n","skew(result_score)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data.info()"]},{"cell_type":"markdown","metadata":{},"source":["Note: A skew value of 0.26 is small enough to model normal distribution, and thus no transformations will have to occur on the target variable for the models themselves"]},{"cell_type":"markdown","metadata":{},"source":["# 2. Linear Regression Models\n"]},{"cell_type":"markdown","metadata":{},"source":["### Model Construction:\n","In the models to be constructed, a variety of parameters will be changed:\n","1. The Polynomial Degree: A higher polynomial degree on the data will fit the data better, at the risk of overfitting.\n","2. The Regularization Technique: Lasso, Ridge, and ElasticNet will be used.\n","3. The Lambda (Alpha Value): Each regularization technique needs an alpha value to determine the amount of regularization applied, a value that is too high can sometimes result in an underfit model.\n","- Each of these models will be created with a Pipeline object, each with a Standard Scaler applied to them."]},{"cell_type":"markdown","metadata":{},"source":["Note: For each model constructed below, each will be compared with Stratified K-Fold Cross Validation, so there will be no explicit split into a testing and training set"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Splitting x and y data\n","X = data.drop(columns=['Scoring Average'])\n","y = data['Scoring Average']\n","\n","X.info()"]},{"cell_type":"code","execution_count":77,"metadata":{},"outputs":[],"source":["import warnings\n","from sklearn.exceptions import ConvergenceWarning\n","\n","# Suppress only ConvergenceWarning\n","warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n","\n","#Parameters to be varied in each model\n","poly_degrees = [x+2 for x in range(3)]\n","alpha_values = np.geomspace(1e-3, 1, 4)\n","\n","#Model result lists\n","lasso_model_scores = pd.DataFrame(index=poly_degrees, columns=alpha_values)\n","ridge_model_scores = pd.DataFrame(index=poly_degrees, columns=alpha_values)\n","enet_model_scores = pd.DataFrame(index=poly_degrees, columns=alpha_values)\n","\n","#Functions that will perform the training\n","\n","#Lasso Function\n","def lasso_model_train(X_data, y_data):\n","    sk_folds = KFold(n_splits=4)\n","    for index1, degree in enumerate(poly_degrees):\n","        for index2, alpha in enumerate(alpha_values):\n","            model = Pipeline([('poly_feat', PolynomialFeatures(degree=degree)), ('ss', StandardScaler()), ('la', Lasso(alpha=alpha, max_iter=1000))])\n","            lasso_model_scores.iloc[index1, index2] = cross_val_score(model, X_data, y_data, cv=sk_folds).mean()\n","\n","#Ridge Function\n","def ridge_model_train(X_data, y_data):\n","    sk_folds = KFold(n_splits=4)\n","    for index1, degree in enumerate(poly_degrees):\n","        for index2, alpha in enumerate(alpha_values):\n","            model = Pipeline([('poly_feat', PolynomialFeatures(degree=degree)), ('ss', StandardScaler()), ('ri', Ridge(alpha=alpha))])\n","            ridge_model_scores.iloc[index1, index2] = cross_val_score(model, X_data, y_data, cv=sk_folds).mean()\n","        \n","#Elastic Net Function\n","def enet_model_train(X_data, y_data):\n","    sk_folds = KFold(n_splits=4)\n","    for index1, degree in enumerate(poly_degrees):\n","        for index2, alpha in enumerate(alpha_values):\n","            model = Pipeline([('poly_feat', PolynomialFeatures(degree=degree)), ('ss', StandardScaler()), ('en', ElasticNet(alpha=alpha, l1_ratio=0.5))])\n","            enet_model_scores.iloc[index1, index2] = cross_val_score(model, X_data, y_data, cv=sk_folds).mean()\n","\n","#Evaluate all models\n","lasso_model_train(X, y)\n","ridge_model_train(X,y)\n","enet_model_train(X, y)"]},{"cell_type":"code","execution_count":78,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0.001</th>\n","      <th>0.010</th>\n","      <th>0.100</th>\n","      <th>1.000</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>0.933773</td>\n","      <td>0.931161</td>\n","      <td>0.906684</td>\n","      <td>-0.011319</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.932314</td>\n","      <td>0.930611</td>\n","      <td>0.907657</td>\n","      <td>-0.011319</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.922673</td>\n","      <td>0.929994</td>\n","      <td>0.908356</td>\n","      <td>-0.011319</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      0.001     0.010     0.100     1.000\n","2  0.933773  0.931161  0.906684 -0.011319\n","3  0.932314  0.930611  0.907657 -0.011319\n","4  0.922673  0.929994  0.908356 -0.011319"]},"execution_count":78,"metadata":{},"output_type":"execute_result"}],"source":["#Lasso Scores\n","lasso_model_scores"]},{"cell_type":"code","execution_count":79,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0.001</th>\n","      <th>0.010</th>\n","      <th>0.100</th>\n","      <th>1.000</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>0.913422</td>\n","      <td>0.921238</td>\n","      <td>0.928688</td>\n","      <td>0.932587</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.859488</td>\n","      <td>0.897683</td>\n","      <td>0.917338</td>\n","      <td>0.926692</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.675225</td>\n","      <td>0.774563</td>\n","      <td>0.877458</td>\n","      <td>0.91347</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      0.001     0.010     0.100     1.000\n","2  0.913422  0.921238  0.928688  0.932587\n","3  0.859488  0.897683  0.917338  0.926692\n","4  0.675225  0.774563  0.877458   0.91347"]},"execution_count":79,"metadata":{},"output_type":"execute_result"}],"source":["#Ridge Scores\n","ridge_model_scores"]},{"cell_type":"code","execution_count":80,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0.001</th>\n","      <th>0.010</th>\n","      <th>0.100</th>\n","      <th>1.000</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>0.933628</td>\n","      <td>0.932104</td>\n","      <td>0.924739</td>\n","      <td>0.409386</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.931599</td>\n","      <td>0.931631</td>\n","      <td>0.92496</td>\n","      <td>0.417694</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.924538</td>\n","      <td>0.931038</td>\n","      <td>0.925189</td>\n","      <td>0.419437</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      0.001     0.010     0.100     1.000\n","2  0.933628  0.932104  0.924739  0.409386\n","3  0.931599  0.931631   0.92496  0.417694\n","4  0.924538  0.931038  0.925189  0.419437"]},"execution_count":80,"metadata":{},"output_type":"execute_result"}],"source":["#Enet Scores\n","enet_model_scores"]},{"cell_type":"markdown","metadata":{},"source":["### Preliminary Analysis\n","<p>From the resulting dataframes above, we can make the following preliminary assumptions:</p>\n","<ol>\n","    <li>Lasso and Enet Models with a high alpha struggled severely</li>\n","    <li>Lasso Models with a low degree and alpha value performed the best</li>\n","    <li>Ridge Models with a low degree and high alpha performed the best</li>\n","    <li>Enet Models with a low degree and mid alpah value performed best</li>\n","</ol>\n","<p>From these assumptions, we can narrow down our dataframes (as shown below)</p>"]},{"cell_type":"code","execution_count":92,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Lasso Values: \n","      0.001     0.010\n","2  0.933773  0.931161\n","3  0.932314  0.930611\n","\n","Ridge Values: \n","        0.1       1.0\n","2  0.928688  0.932587\n","3  0.917338  0.926692\n","\n","Enet Values: \n","       0.01      0.10\n","2  0.932104  0.924739\n","3  0.931631   0.92496\n","\n"]}],"source":["best_lasso = lasso_model_scores.iloc[:2, :2]\n","best_ridge = ridge_model_scores.iloc[:2, 2:]\n","best_enet = enet_model_scores.iloc[:2, 1:3]\n","print(f'Lasso Values: \\n{best_lasso}\\n')\n","print(f'Ridge Values: \\n{best_ridge}\\n')\n","print(f'Enet Values: \\n{best_enet}\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# 4. Insights and key findings\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# 5. Next Steps\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## <h3 align=\"center\"> Â© IBM Corporation 2020. All rights reserved. <h3/>\n"]}],"metadata":{"kernelspec":{"display_name":"venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":4}
